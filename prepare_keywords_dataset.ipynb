{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dedicated to doctor professor Oren Kurland\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def get_num_of_words(list_of_sentences):\n",
    "    num = 0\n",
    "    for sen in list_of_sentences:\n",
    "        num += len(sen.split())\n",
    "    return num\n",
    "\n",
    "\n",
    "def calc_tf_score(list_of_sentences, num_of_words):\n",
    "    tf_score = defaultdict(int)\n",
    "    for sen in list_of_sentences:\n",
    "        for word in sen:\n",
    "            if word not in stop_words:\n",
    "                tf_score[word] += 1\n",
    "    # Dividing by total_word_length for each dictionary element\n",
    "    tf_score.update((x, y / int(num_of_words)) for x, y in tf_score.items())\n",
    "    return tf_score\n",
    "\n",
    "\n",
    "def check_sent(word, sentences):\n",
    "    final = [all([w in x for w in word]) for x in sentences]\n",
    "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    return int(len(sent_len))\n",
    "\n",
    "\n",
    "def calc_idf_score(list_of_sentences, num_of_sens):\n",
    "    idf_score = defaultdict(int)\n",
    "    for sen in list_of_sentences:\n",
    "        for word in sen:\n",
    "            if word not in stop_words:\n",
    "                idf_score[word] = check_sent(word, list_of_sentences)\n",
    "    # Dividing by total_word_length for each dictionary element\n",
    "    idf_score.update((x, math.log(int(num_of_sens)/y)) for x, y in idf_score.items())\n",
    "    return idf_score\n",
    "\n",
    "\n",
    "def tf_idf_dict(list_of_sentences):\n",
    "    \"\"\"\n",
    "    calc tfidf score to all words in a list of sentences\n",
    "    :param list_of_sentences: the list of all sentences\n",
    "    :return: tf_idf score dict\n",
    "    \"\"\"\n",
    "    num_of_sen = len(list_of_sentences)\n",
    "    num_of_words = get_num_of_words(list_of_sentences)\n",
    "    tf_score = calc_tf_score(list_of_sentences, num_of_words)\n",
    "    idf_score = calc_idf_score(list_of_sentences, num_of_sen)\n",
    "    tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "    return tf_idf_score\n",
    "\n",
    "\n",
    "def get_key_words_for_sen(sen, tf_idf_score, lower_threshold, upper_threshold=10000000):\n",
    "    \"\"\"\n",
    "    get keywords for a sentence\n",
    "    :param sen: the sentence\n",
    "    :param tf_idf_score: tf_idf_score dict like above\n",
    "    :param lower_threshold: lower bound on tfidf score\n",
    "    :param upper_threshold: upper bound on tfidf score\n",
    "    :return: keywords for sentence sen\n",
    "    \"\"\"\n",
    "    keywords = []\n",
    "    for word in sen:\n",
    "        if tf_idf_score[word] > lower_threshold and tf_idf_score[word] < upper_threshold:\n",
    "            keywords.append(word)\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def pipeline(list_of_sentences, lower_threshold, upper_threshold=10000000):\n",
    "    \"\"\"\n",
    "    do everything above for a list of sentences\n",
    "    :param list_of_sentences: the list of all sentences\n",
    "    :param lower_threshold: lower bound on tfidf score\n",
    "    :param upper_threshold: upper bound on tfidf score\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    tf_idf_score = tf_idf_dict(list_of_sentences)\n",
    "    key_list = []\n",
    "    for sentence in list_of_sentences:\n",
    "        key_list.append(get_key_words_for_sen(sentence, tf_idf_score, lower_threshold, upper_threshold))\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sentence\"] = list_of_sentences\n",
    "    df[\"keywords\"] = key_list\n",
    "    df.to_csv(\"keywords_ds.csv\")\n",
    "    df.to_pickle(\"keywords_ds.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"marriage\" isn't keeping up with the times.  a...</td>\n",
       "      <td>marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoning marriage allows for people to grow ...</td>\n",
       "      <td>marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abandoning weddings would offend many religiou...</td>\n",
       "      <td>marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as society and values change, marriage is no l...</td>\n",
       "      <td>marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by adopting such practice we can get rid of al...</td>\n",
       "      <td>marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17288</th>\n",
       "      <td>We should subsidize embryonic stem cell resear...</td>\n",
       "      <td>embryonic cel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17289</th>\n",
       "      <td>we should subsidize embryonic stem cell resear...</td>\n",
       "      <td>embryonic cel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17290</th>\n",
       "      <td>we shouldn't subsidize embryonic stem cell res...</td>\n",
       "      <td>embryonic cel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17291</th>\n",
       "      <td>we shouldn't subsidize stem cell research beca...</td>\n",
       "      <td>embryonic cel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17292</th>\n",
       "      <td>you cannot use public money to advance researc...</td>\n",
       "      <td>embryonic cel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17293 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence          topic\n",
       "0      \"marriage\" isn't keeping up with the times.  a...       marriage\n",
       "1      abandoning marriage allows for people to grow ...       marriage\n",
       "2      Abandoning weddings would offend many religiou...       marriage\n",
       "3      as society and values change, marriage is no l...       marriage\n",
       "4      by adopting such practice we can get rid of al...       marriage\n",
       "...                                                  ...            ...\n",
       "17288  We should subsidize embryonic stem cell resear...  embryonic cel\n",
       "17289  we should subsidize embryonic stem cell resear...  embryonic cel\n",
       "17290  we shouldn't subsidize embryonic stem cell res...  embryonic cel\n",
       "17291  we shouldn't subsidize stem cell research beca...  embryonic cel\n",
       "17292  you cannot use public money to advance researc...  embryonic cel\n",
       "\n",
       "[17293 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./IBM_Debater_(R)/IBM_Debater_(R)_arg_quality_rank_30k/arg_quality_rank_30k.csv')\n",
    "df = df[df.WA > 0.8]\n",
    "df_topics = pd.read_csv('./30k_topicks.csv')\n",
    "df_no_keywords = df.merge(df_topics, on='topic')\n",
    "df_no_keywords = df_no_keywords[['argument', 'adj_topic']].rename(columns={'argument': 'sentence', 'adj_topic': 'topic'})\n",
    "df_no_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('single_topic.csv')\n",
    "# df_winner = pd.DataFrame(df['Winner'].to_numpy(), columns=['sentence'])\n",
    "# df_loser = pd.DataFrame(df['Loser'].to_numpy(), columns=['sentence'])\n",
    "# df = pd.concat([df_winner, df_loser]).reset_index()[['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_no_keywords['sentence'].unique(), columns=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sent_tf_idf_dict = tf_idf_dict(df['sentence'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['sentence'].tolist()\n",
    "vectorizer = TfidfVectorizer(stop_words=list(stop_words), lowercase=True)\n",
    "doc_term_matrix = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_\n",
    "doc_term_matrix = doc_term_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_words_for_sen_egor(sen, sen_id, vocab, doc_term_matrix, lower_threshold, upper_threshold=10000000):\n",
    "    \"\"\"\n",
    "    get keywords for a sentence\n",
    "    :param sen: the sentence\n",
    "    :param tf_idf_score: tf_idf_score dict like above\n",
    "    :param lower_threshold: lower bound on tfidf score\n",
    "    :param upper_threshold: upper bound on tfidf score\n",
    "    :return: keywords for sentence sen\n",
    "    \"\"\"\n",
    "    keywords = set()\n",
    "    all_words = set()\n",
    "    for word in sen.split():\n",
    "        word = word.lower()\n",
    "        if word not in vocab or word in keywords:\n",
    "            continue\n",
    "        word_index = vocab[word.lower()]\n",
    "        tf_idf_score = doc_term_matrix[sen_id][word_index]\n",
    "        if tf_idf_score > lower_threshold and tf_idf_score < upper_threshold:\n",
    "            keywords.add((word, tf_idf_score))\n",
    "        all_words.add((word, tf_idf_score))\n",
    "    keywords = sorted(list(keywords), key=lambda x: x[1], reverse=True)[:6]\n",
    "    all_words = sorted(list(all_words), key=lambda x: x[1], reverse=True)[:6]\n",
    "    if len(keywords) >= 2:\n",
    "        return [word for word, _ in keywords]\n",
    "    else:\n",
    "        return [word for word, _ in all_words[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_\n",
    "topics = df_no_keywords['topic']\n",
    "keywords_list = []\n",
    "for sent_index, topic in zip(range(len(corpus)), topics):\n",
    "    keywords = get_key_words_for_sen_egor(corpus[sent_index], sent_index, vocab, doc_term_matrix,\n",
    "                                          lower_threshold=0.28, upper_threshold=1)\n",
    "#     keywords_list.append([topic]+keywords)\n",
    "    keywords_list.append(topic+': '+', '.join(keywords))\n",
    "df = pd.DataFrame()\n",
    "df[\"keywords\"] = keywords_list\n",
    "df[\"sentence\"] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30k_keywords = df.merge(df_no_keywords, on='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30k_keywords.to_csv('keywords_30k.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
